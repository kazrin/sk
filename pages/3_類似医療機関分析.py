import streamlit as st
import pandas as pd
import ast
from utils import load_raw_data, display_institution_basic_info

st.title("ğŸ” é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢åˆ†æ")

def calculate_jaccard_similarity(set1, set2):
    """Calculate Jaccard similarity coefficient between two sets"""
    if len(set1) == 0 and len(set2) == 0:
        return 1.0
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union if union > 0 else 0.0

@st.cache_data(hash_funcs={dict: lambda x: str(x), list: lambda x: str(x)})
def find_similar_institutions(target_institution, df):
    """Find similar institutions based on filing contents"""
    # Get target institution's number first
    target_institution_data = df[df['åŒ»ç™‚æ©Ÿé–¢åç§°'] == target_institution]
    if len(target_institution_data) == 0:
        return pd.DataFrame()
    
    target_institution_number = target_institution_data.iloc[0]['åŒ»ç™‚æ©Ÿé–¢ç•ªå·']
    
    # Pre-group all institutions' filings by institution number (more accurate than name)
    institution_filings_dict = (
        df.groupby('åŒ»ç™‚æ©Ÿé–¢ç•ªå·')['å—ç†å±Šå‡ºåç§°']
        .apply(lambda x: set(x.dropna().unique()))
        .to_dict()
    )
    
    # Get institution name mapping (number -> name)
    institution_name_mapping = (
        df.groupby('åŒ»ç™‚æ©Ÿé–¢ç•ªå·')['åŒ»ç™‚æ©Ÿé–¢åç§°']
        .first()
        .to_dict()
    )
    
    # Get bed counts for each institution using drop_duplicates
    # This is more efficient than looping
    unique_institutions = df[['åŒ»ç™‚æ©Ÿé–¢ç•ªå·', 'ç—…åºŠæ•°']].drop_duplicates(subset='åŒ»ç™‚æ©Ÿé–¢ç•ªå·', keep='first')
    
    # Convert to dict, handling string to dict conversion
    institution_bed_counts = {}
    for _, row in unique_institutions.iterrows():
        inst_num = row['åŒ»ç™‚æ©Ÿé–¢ç•ªå·']
        bed_count = row['ç—…åºŠæ•°']
        
        # If it's a string (JSON-like), convert to dict
        if isinstance(bed_count, str):
            try:
                institution_bed_counts[inst_num] = ast.literal_eval(bed_count)
            except:
                institution_bed_counts[inst_num] = {}
        # If already a dict, use as is
        elif isinstance(bed_count, dict):
            institution_bed_counts[inst_num] = bed_count
        else:
            institution_bed_counts[inst_num] = {}
    
    # Get target institution's filings
    target_filings = institution_filings_dict.get(target_institution_number, set())
    
    if len(target_filings) == 0:
        return pd.DataFrame()
    
    # Calculate similarities for all other institutions
    similarities = []
    for institution_number, filings in institution_filings_dict.items():
        if institution_number == target_institution_number or len(filings) == 0:
            continue
        
        similarity = calculate_jaccard_similarity(target_filings, filings)
        overlap = target_filings.intersection(filings)
        unique_to_target = target_filings - filings
        unique_to_institution = filings - target_filings
        
        # Get bed count from our mapping (should already be a dict)
        bed_count = institution_bed_counts.get(institution_number, {})
        
        # Ensure it's a dict and make a copy
        if not isinstance(bed_count, dict):
            bed_count = {}
        else:
            bed_count = dict(bed_count)
        
        # Extract bed types from bed count dict (keys are bed types)
        bed_types = []
        if bed_count:
            bed_types = [str(k).strip() for k in bed_count.keys() if k is not None and str(k).strip()]
            bed_types = sorted([bt for bt in bed_types if bt])  # Remove empty strings and sort
        
        # Get institution name
        institution_name = institution_name_mapping.get(institution_number, f"åŒ»ç™‚æ©Ÿé–¢ç•ªå·: {institution_number}")
        
        similarities.append({
            'åŒ»ç™‚æ©Ÿé–¢åç§°': institution_name,
            'ç—…åºŠç¨®é¡': bed_types,
            'ç—…åºŠæ•°': bed_count,
            'é¡ä¼¼åº¦': similarity,
            'é‡è¤‡å±Šå‡ºæ•°': len(overlap),
            'å¯¾è±¡æ©Ÿé–¢ã®ã¿ã®å±Šå‡ºæ•°': len(unique_to_target),
            'é¡ä¼¼æ©Ÿé–¢ã®ã¿ã®å±Šå‡ºæ•°': len(unique_to_institution),
        })
    
    # Convert to DataFrame and sort by similarity
    if not similarities:
        return pd.DataFrame()
    
    result_df = pd.DataFrame(similarities)
    
    # Ensureç—…åºŠæ•° column is treated as object type to preserve dicts
    if 'ç—…åºŠæ•°' in result_df.columns:
        result_df['ç—…åºŠæ•°'] = result_df['ç—…åºŠæ•°'].astype(object)
    
    if len(result_df) > 0:
        result_df = result_df.sort_values('é¡ä¼¼åº¦', ascending=False)
    
    return result_df

# Get selected institution from session state
selected_institution = st.session_state.get('selected_institution', None)

if selected_institution:
    st.write(f"### å¯¾è±¡åŒ»ç™‚æ©Ÿé–¢: {selected_institution}")
    
    # Load data
    df = load_raw_data()
    
    # Filter data for selected institution
    institution_data = df[df['åŒ»ç™‚æ©Ÿé–¢åç§°'] == selected_institution]
    
    # Display basic information
    row_data = institution_data.iloc[0]
    display_institution_basic_info(row_data)
    
    st.divider()
    
    # Calculate and display similar institutions
    st.write("### ğŸ” é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢åˆ†æ")
    
    with st.spinner("é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢ã‚’è¨ˆç®—ä¸­..."):
        similar_df = find_similar_institutions(selected_institution, df)
    
    if len(similar_df) > 0:
        # Get target institution's bed types for default filter
        target_bed_count = row_data.get('ç—…åºŠæ•°', {})
        target_bed_types = []
        if isinstance(target_bed_count, str):
            try:
                target_bed_count = ast.literal_eval(target_bed_count)
            except:
                target_bed_count = {}
        if isinstance(target_bed_count, dict):
            target_bed_types = [str(k).strip() for k in target_bed_count.keys() if k is not None and str(k).strip()]
        
        # Get all available bed types from similar institutions
        all_bed_types = set()
        for bed_types_list in similar_df['ç—…åºŠç¨®é¡']:
            if isinstance(bed_types_list, list):
                # Filter out None values and empty strings, and strip whitespace
                cleaned_types = [str(bt).strip() for bt in bed_types_list if bt is not None and str(bt).strip()]
                all_bed_types.update(cleaned_types)
        all_bed_types = sorted([bt for bt in all_bed_types if bt])  # Remove empty strings
        
        # Initialize selected_bed_types
        selected_bed_types = []
        bed_count_filters = {}
        
        # Filter section header with expander
        with st.expander("### ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶", expanded=False):
            st.caption("é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢ã®æ¤œç´¢çµæœã‚’çµã‚Šè¾¼ã¿ã¾ã™")
            
            # Bed type filter (multiselect) - default to target institution's bed types only
            if all_bed_types:
                # Default to only the target institution's bed types
                default_selection = [bt for bt in target_bed_types if bt in all_bed_types]
                selected_bed_types = st.multiselect(
                    "ç—…åºŠç¨®é¡ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼:",
                    options=all_bed_types,
                    default=default_selection,
                    key='bed_type_filter',
                    help="é¸æŠã—ãŸç—…åºŠç¨®é¡ã‚’æŒã¤åŒ»ç™‚æ©Ÿé–¢ã®ã¿ã‚’è¡¨ç¤ºã—ã¾ã™"
                )
                
                # Filter by selected bed types
                if selected_bed_types:
                    # Filter institutions that have at least one of the selected bed types
                    mask = similar_df['ç—…åºŠç¨®é¡'].apply(
                        lambda x: bool(set(x).intersection(set(selected_bed_types)))
                    )
                    filtered_df = similar_df[mask].copy()
                else:
                    # If no selection, show all
                    filtered_df = similar_df.copy()
            else:
                # No bed types available, show all
                filtered_df = similar_df.copy()
            
            # Bed count filter by bed type
            if selected_bed_types:
                st.write("")
                st.caption("é¸æŠã—ãŸç—…åºŠç¨®é¡ã®ç—…åºŠæ•°ç¯„å›²ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã—ã¾ã™")
        
            # Get max bed counts for each selected bed type from filtered_df
            bed_count_max = {}
            if selected_bed_types and len(filtered_df) > 0:
                # Get unique institutions with their bed counts (using åŒ»ç™‚æ©Ÿé–¢åç§° since åŒ»ç™‚æ©Ÿé–¢ç•ªå· is not in similar_df)
                unique_institutions = filtered_df[['åŒ»ç™‚æ©Ÿé–¢åç§°', 'ç—…åºŠæ•°']].drop_duplicates(subset='åŒ»ç™‚æ©Ÿé–¢åç§°', keep='first')
                
                # Collect all bed counts for all selected bed types in a single pass
                bed_counts_by_type = {bed_type: [] for bed_type in selected_bed_types}
                
                # Single loop through unique institutions (direct Series iteration is faster than iterrows)
                bed_count_series = unique_institutions['ç—…åºŠæ•°']
                for bed_count_dict in bed_count_series:
                    if isinstance(bed_count_dict, dict):
                        for bed_type in selected_bed_types:
                            if bed_type in bed_count_dict:
                                bed_num = bed_count_dict[bed_type]
                                if isinstance(bed_num, (int, float)) and bed_num is not None:
                                    bed_counts_by_type[bed_type].append(bed_num)
                
                # Calculate max for each bed type
                for bed_type, bed_counts in bed_counts_by_type.items():
                    if bed_counts:
                        bed_count_max[bed_type] = int(max(bed_counts))
            
            # Create bed count filters for each selected bed type (vertical layout)
            if bed_count_max:
                for bed_type, max_val in bed_count_max.items():
                    # Use slider for bed count range (min is always 1)
                    bed_count_range = st.slider(
                        f"{bed_type}ã®ç—…åºŠæ•°",
                        min_value=1,
                        max_value=max_val,
                        value=(1, max_val),
                        key=f'bed_count_filter_{bed_type}',
                        help=f"ç¯„å›²: 1ã€œ{max_val}åºŠ"
                    )
                    bed_count_filters[bed_type] = bed_count_range
        
        # Apply bed count filters
        if bed_count_filters:
            def passes_bed_count_filter(row):
                """Check if institution passes bed count filters"""
                bed_count_dict = row['ç—…åºŠæ•°']
                if not isinstance(bed_count_dict, dict):
                    return True  # Include records without bed count data
                
                # Check if ALL selected bed type filters are satisfied (AND condition)
                for bed_type, (min_val, max_val) in bed_count_filters.items():
                    # If this bed type exists in the institution's bed count
                    if bed_type in bed_count_dict:
                        bed_num = bed_count_dict[bed_type]
                        if isinstance(bed_num, (int, float)) and bed_num is not None:
                            # Check if it's within the range
                            if not (min_val <= bed_num <= max_val):
                                return False  # Failed this filter condition
                        else:
                            return False  # Invalid bed number
                    else:
                        # If bed type is not in the institution, include it (True)
                        continue  # Skip this filter condition and check others
                
                # All conditions passed
                return True
            
            if len(filtered_df) > 0:
                mask = filtered_df.apply(passes_bed_count_filter, axis=1)
                filtered_df = filtered_df[mask].copy()
        
        st.write(f"**è¡¨ç¤ºä»¶æ•°: {len(filtered_df)}ä»¶ (å…¨{len(similar_df)}ä»¶ä¸­)**")
        
        # Display detailed table
        display_columns = ['åŒ»ç™‚æ©Ÿé–¢åç§°', 'ç—…åºŠæ•°', 'é¡ä¼¼åº¦', 'é‡è¤‡å±Šå‡ºæ•°', 'å¯¾è±¡æ©Ÿé–¢ã®ã¿ã®å±Šå‡ºæ•°', 'é¡ä¼¼æ©Ÿé–¢ã®ã¿ã®å±Šå‡ºæ•°']
        
        # Format similarity as percentage and format bed count for display
        # Use deep copy to ensure dicts are preserved
        display_df = filtered_df[display_columns].copy(deep=True)
        display_df['é¡ä¼¼åº¦'] = display_df['é¡ä¼¼åº¦'].apply(lambda x: f"{x:.1%}")
        
        # Format bed count (dict) to display string
        def format_bed_count(bed_count):
            """Format bed count dict to display string"""
            # Convert string to dict if needed
            if isinstance(bed_count, str):
                try:
                    bed_count = ast.literal_eval(bed_count)
                except:
                    return ""
            
            # Handle non-dict cases
            if bed_count is None:
                return ""
            if not isinstance(bed_count, dict):
                return ""
            if not bed_count:  # Empty dict
                return ""
            
            bed_parts = []
            for bed_type, bed_number in bed_count.items():
                # Skip if both are None
                if bed_type is None and bed_number is None:
                    continue
                # Handle different combinations
                if bed_type is None and bed_number is not None:
                    bed_parts.append(str(bed_number))
                elif bed_type is not None and bed_number is None:
                    bed_parts.append(str(bed_type))
                elif bed_type is not None and bed_number is not None:
                    bed_parts.append(f"{bed_type} {bed_number}")
            return " / ".join(bed_parts)
        
        display_df['ç—…åºŠæ•°'] = display_df['ç—…åºŠæ•°'].apply(format_bed_count)
        
        st.dataframe(
            display_df,
            width='stretch',
            hide_index=True
        )
        
        # Create cross-tabulation table for top 20 similar institutions
        st.write("### ğŸ“Š ç”³è«‹æ–½è¨­åŸºæº–ã®å±Šå‡ºçŠ¶æ³ï¼ˆé¡ä¼¼åº¦ä¸Šä½20ä»¶ï¼‰")
        
        # Get top 20 institutions
        top_20_df = filtered_df.head(20).copy()
        top_20_institutions = top_20_df['åŒ»ç™‚æ©Ÿé–¢åç§°'].tolist()
        
        # Pre-compute institution filings by institution number (for performance)
        institution_filings_by_number = (
            df.groupby('åŒ»ç™‚æ©Ÿé–¢ç•ªå·')['å—ç†å±Šå‡ºåç§°']
            .apply(lambda x: set(x.dropna().unique()))
            .to_dict()
        )
        
        # Get institution numbers for these institutions
        institution_number_mapping = (
            df.groupby('åŒ»ç™‚æ©Ÿé–¢åç§°')['åŒ»ç™‚æ©Ÿé–¢ç•ªå·']
            .first()
            .to_dict()
        )
        
        # Create mapping from å—ç†å±Šå‡ºåç§° to å—ç†è¨˜å· (1-to-1 relationship)
        if 'å—ç†è¨˜å·' in df.columns:
            filing_name_to_symbol = (
                df.groupby('å—ç†å±Šå‡ºåç§°')['å—ç†è¨˜å·']
                .first()
                .to_dict()
            )
        else:
            filing_name_to_symbol = {}
        
        # Get all filing types (æ–½è¨­åŸºæº–) from target and top 20 institutions
        all_filing_types = set()
        
        # Get target institution's filing types
        target_institution_number = institution_data.iloc[0]['åŒ»ç™‚æ©Ÿé–¢ç•ªå·']
        target_filing_types = institution_filings_by_number.get(target_institution_number, set())
        all_filing_types.update(target_filing_types)
        
        # Get top 20 institutions' filing types
        for institution_name in top_20_institutions:
            institution_number = institution_number_mapping.get(institution_name)
            if institution_number:
                filing_types = institution_filings_by_number.get(institution_number, set())
                all_filing_types.update(filing_types)
        
        all_filing_types = sorted(list(all_filing_types))
        
        if all_filing_types and top_20_institutions:
            # Build data for cross-tabulation
            rows_data = []
            
            for filing_type in all_filing_types:
                row_data = {
                    'å—ç†å±Šå‡ºåç§°': filing_type,
                    'å—ç†è¨˜å·': filing_name_to_symbol.get(filing_type, '')
                }
                
                # First, add target institution's filing status
                target_filing_types_set = institution_filings_by_number.get(target_institution_number, set())
                row_data[selected_institution] = filing_type in target_filing_types_set
                
                # Then, add top 20 institutions' filing status
                for institution_name in top_20_institutions:
                    institution_number = institution_number_mapping.get(institution_name)
                    if institution_number:
                        filing_types_set = institution_filings_by_number.get(institution_number, set())
                        row_data[institution_name] = filing_type in filing_types_set
                    else:
                        row_data[institution_name] = False
                
                rows_data.append(row_data)
            
            # Create DataFrame with å—ç†å±Šå‡ºåç§° and å—ç†è¨˜å· as columns
            cross_tab_df = pd.DataFrame(rows_data)
            # Set å—ç†å±Šå‡ºåç§° as index for filtering, but we'll display it as a column
            cross_tab_df = cross_tab_df.set_index('å—ç†å±Šå‡ºåç§°')
            
            # Filter: Show only filing types that target institution has NOT filed
            show_only_unfiled = st.checkbox(
                "å¯¾è±¡åŒ»ç™‚æ©Ÿé–¢ãŒæœªå±Šã®æ–½è¨­åŸºæº–ã®ã¿è¡¨ç¤º",
                value=False,
                key='show_only_unfiled_filter'
            )
            
            if show_only_unfiled:
                # Filter rows where target institution column is False
                filtered_cross_tab_df = cross_tab_df[cross_tab_df[selected_institution] == False].copy()
            else:
                filtered_cross_tab_df = cross_tab_df.copy()
            
            # Reset index to display å—ç†å±Šå‡ºåç§° as a regular column
            display_df = filtered_cross_tab_df.reset_index()
            
            # Reorder columns: å—ç†å±Šå‡ºåç§°, å—ç†è¨˜å·, then institution columns
            institution_columns = [selected_institution] + top_20_institutions
            display_columns = ['å—ç†å±Šå‡ºåç§°', 'å—ç†è¨˜å·'] + institution_columns
            display_df = display_df[display_columns]
            
            # Display the table
            st.dataframe(
                display_df,
                width='stretch',
                hide_index=True
            )
        
        # Add explanation about Jaccard similarity at the end
        st.divider()
        st.write("### ğŸ“– é¡ä¼¼åº¦ã®è¨ˆç®—æ–¹æ³•ã«ã¤ã„ã¦")
        st.markdown("""
        **Jaccardä¿‚æ•°ï¼ˆJaccard similarity coefficientï¼‰**ã‚’ä½¿ç”¨ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™ã€‚
        
        Jaccardä¿‚æ•°ã¯ã€2ã¤ã®é›†åˆãŒã©ã‚Œã ã‘ä¼¼ã¦ã„ã‚‹ã‹ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã€ä»¥ä¸‹ã®å¼ã§è¨ˆç®—ã•ã‚Œã¾ã™ï¼š
        
        $$
        J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|} = \\frac{\\text{å…±é€šè¦ç´ æ•°}}{\\text{å…¨è¦ç´ æ•°}}
        $$
        
        **å…·ä½“ä¾‹ï¼š**
        
        åŒ»ç™‚æ©Ÿé–¢Aã®å±Šå‡ºæ–½è¨­åŸºæº–ï¼š`{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™1, ç‰¹æ²è¨ºç™‚æ–™2}`
        
        åŒ»ç™‚æ©Ÿé–¢Bã®å±Šå‡ºæ–½è¨­åŸºæº–ï¼š`{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™2, ç‰¹æ²è¨ºç™‚æ–™3}`
        
        - **å…±é€šã™ã‚‹å±Šå‡ºï¼ˆç©é›†åˆï¼‰**: `{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™2}` â†’ 2å€‹
        - **ã™ã¹ã¦ã®å±Šå‡ºï¼ˆå’Œé›†åˆï¼‰**: `{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™1, ç‰¹æ²è¨ºç™‚æ–™2, ç‰¹æ²è¨ºç™‚æ–™3}` â†’ 4å€‹
        - **Jaccardä¿‚æ•°**: 2 Ã· 4 = 0.5 (50%)
        
        Jaccardä¿‚æ•°ã¯0ã‹ã‚‰1ã®å€¤ã‚’å–ã‚Šã€1ã«è¿‘ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ãã€0ã«è¿‘ã„ã»ã©é¡ä¼¼åº¦ãŒä½ã„ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
        """)
else:
    st.info("åŒ»ç™‚æ©Ÿé–¢æ¤œç´¢ãƒšãƒ¼ã‚¸ã‹ã‚‰åŒ»ç™‚æ©Ÿé–¢ã‚’æ¤œç´¢ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚")
