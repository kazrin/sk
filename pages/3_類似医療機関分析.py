import streamlit as st
import pandas as pd
import ast
from utils import load_raw_data, display_institution_basic_info
from dataframes import ShisetsuKijunDataFrame, JaccardSimilarityDataFrame

st.title("ğŸ” é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢åˆ†æ")

@st.cache_data(hash_funcs={dict: lambda x: str(x), list: lambda x: str(x)})
def find_similar_institutions(target_institution, _df):
    """Find similar institutions based on filing contents"""
    # Convert to ShisetsuKijunDataFrame if not already
    if not isinstance(_df, ShisetsuKijunDataFrame):
        _df = ShisetsuKijunDataFrame(_df)
    
    return JaccardSimilarityDataFrame.from_shisetsu_kijun(_df, target_institution)

# Get selected institution from session state
selected_institution = st.session_state.get('selected_institution', None)

if selected_institution:
    st.write(f"### å¯¾è±¡åŒ»ç™‚æ©Ÿé–¢: {selected_institution}")
    
    # Load data
    df = load_raw_data()
    
    # Filter data for selected institution
    institution_data = df.filter_by_exact_institution_name(selected_institution)
    
    # Display basic information
    row_data = institution_data.iloc[0]
    display_institution_basic_info(row_data)
    
    st.divider()
    
    # Calculate and display similar institutions
    st.write("### ğŸ” é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢åˆ†æ")
    
    with st.spinner("é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢ã‚’è¨ˆç®—ä¸­..."):
        similar_df = find_similar_institutions(selected_institution, df)
    
    if len(similar_df) > 0:
        # Get target institution's bed types for default filter
        target_bed_count = row_data.get('ç—…åºŠæ•°', {})
        target_bed_types = []
        if isinstance(target_bed_count, str):
            try:
                target_bed_count = ast.literal_eval(target_bed_count)
            except:
                target_bed_count = {}
        if isinstance(target_bed_count, dict):
            target_bed_types = [str(k).strip() for k in target_bed_count.keys() if k is not None and str(k).strip()]
        
        # Get all available bed types from similar institutions
        from dataframes import JaccardSimilarityDataFrame
        # similar_df is already JaccardSimilarityDataFrame from calculate_jaccard_similarity
        all_bed_types = similar_df.get_all_bed_types()
        
        # Initialize selected_bed_types
        selected_bed_types = []
        bed_count_filters = {}
        
        # Filter section header with expander
        with st.expander("### ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶", expanded=False):
            st.caption("é¡ä¼¼åŒ»ç™‚æ©Ÿé–¢ã®æ¤œç´¢çµæœã‚’çµã‚Šè¾¼ã¿ã¾ã™")
            
            # Bed type filter (multiselect) - default to target institution's bed types only
            if all_bed_types:
                # Default to only the target institution's bed types
                default_selection = [bt for bt in target_bed_types if bt in all_bed_types]
                selected_bed_types = st.multiselect(
                    "ç—…åºŠç¨®é¡ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼:",
                    options=all_bed_types,
                    default=default_selection,
                    key='bed_type_filter',
                    help="é¸æŠã—ãŸç—…åºŠç¨®é¡ã‚’æŒã¤åŒ»ç™‚æ©Ÿé–¢ã®ã¿ã‚’è¡¨ç¤ºã—ã¾ã™"
                )
                
                # Filter by selected bed types
                if selected_bed_types:
                    filtered_df = similar_df.filter_by_bed_types(selected_bed_types)
                else:
                    # If no selection, show all
                    filtered_df = similar_df.copy()
            else:
                # No bed types available, show all
                filtered_df = similar_df.copy()
            
            # Bed count filter by bed type
            if selected_bed_types:
                st.write("")
                st.caption("é¸æŠã—ãŸç—…åºŠç¨®é¡ã®ç—…åºŠæ•°ç¯„å›²ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã—ã¾ã™")
        
            # Get max bed counts for each selected bed type from filtered_df
            if selected_bed_types and len(filtered_df) > 0:
                # Get max bed counts (JaccardSimilarityDataFrame has this method)
                bed_count_max = filtered_df.get_bed_count_max(selected_bed_types)
                
                # Create bed count filters for each selected bed type (vertical layout)
                if bed_count_max:
                    for bed_type, max_val in bed_count_max.items():
                        # Use slider for bed count range (min is always 1)
                        bed_count_range = st.slider(
                            f"{bed_type}ã®ç—…åºŠæ•°",
                            min_value=1,
                            max_value=max_val,
                            value=(1, max_val),
                            key=f'bed_count_filter_{bed_type}',
                            help=f"ç¯„å›²: 1ã€œ{max_val}åºŠ"
                        )
                        bed_count_filters[bed_type] = bed_count_range
        
        # Apply bed count filters
        if bed_count_filters and len(filtered_df) > 0:
            # JaccardSimilarityDataFrame has this method
            filtered_df = filtered_df.filter_by_bed_counts_generic(bed_count_filters)
        
        st.write(f"**è¡¨ç¤ºä»¶æ•°: {len(filtered_df)}ä»¶ (å…¨{len(similar_df)}ä»¶ä¸­)**")
        
        # Display detailed table
        display_columns = ['åŒ»ç™‚æ©Ÿé–¢åç§°', 'ç—…åºŠæ•°', 'é¡ä¼¼åº¦', 'é‡è¤‡å±Šå‡ºæ•°', 'å¯¾è±¡æ©Ÿé–¢ã®ã¿ã®å±Šå‡ºæ•°', 'é¡ä¼¼æ©Ÿé–¢ã®ã¿ã®å±Šå‡ºæ•°']
        
        # Format similarity as percentage and format bed count for display
        # Use deep copy to ensure dicts are preserved
        display_df = filtered_df[display_columns].copy(deep=True)
        display_df['é¡ä¼¼åº¦'] = display_df['é¡ä¼¼åº¦'].apply(lambda x: f"{x:.1%}")
        
        # Format bed count (dict) to display string
        def format_bed_count(bed_count):
            """Format bed count dict to display string"""
            # Convert string to dict if needed
            if isinstance(bed_count, str):
                try:
                    bed_count = ast.literal_eval(bed_count)
                except:
                    return ""
            
            # Handle non-dict cases
            if bed_count is None:
                return ""
            if not isinstance(bed_count, dict):
                return ""
            if not bed_count:  # Empty dict
                return ""
            
            bed_parts = []
            for bed_type, bed_number in bed_count.items():
                # Skip if both are None
                if bed_type is None and bed_number is None:
                    continue
                # Handle different combinations
                if bed_type is None and bed_number is not None:
                    bed_parts.append(str(bed_number))
                elif bed_type is not None and bed_number is None:
                    bed_parts.append(str(bed_type))
                elif bed_type is not None and bed_number is not None:
                    bed_parts.append(f"{bed_type} {bed_number}")
            return " / ".join(bed_parts)
        
        display_df['ç—…åºŠæ•°'] = display_df['ç—…åºŠæ•°'].apply(format_bed_count)
        
        st.dataframe(
            display_df,
            width='stretch',
            hide_index=True
        )
        
        # Create cross-tabulation table for top 20 similar institutions
        st.write("### ğŸ“Š ç”³è«‹æ–½è¨­åŸºæº–ã®å±Šå‡ºçŠ¶æ³ï¼ˆé¡ä¼¼åº¦ä¸Šä½20ä»¶ï¼‰")
        
        # Get top 20 institutions
        top_20_df = filtered_df.head(20).copy()
        top_20_institutions = top_20_df['åŒ»ç™‚æ©Ÿé–¢åç§°'].tolist()
        
        # Pre-compute institution filings by institution number (for performance)
        institution_filings_by_number = (
            df.groupby('åŒ»ç™‚æ©Ÿé–¢ç•ªå·')['å—ç†å±Šå‡ºåç§°']
            .apply(lambda x: set(x.dropna().unique()))
            .to_dict()
        )
        
        # Get institution numbers for these institutions
        institution_number_mapping = (
            df.groupby('åŒ»ç™‚æ©Ÿé–¢åç§°')['åŒ»ç™‚æ©Ÿé–¢ç•ªå·']
            .first()
            .to_dict()
        )
        
        # Create mapping from å—ç†å±Šå‡ºåç§° to å—ç†è¨˜å· (1-to-1 relationship)
        if 'å—ç†è¨˜å·' in df.columns:
            filing_name_to_symbol = (
                df.groupby('å—ç†å±Šå‡ºåç§°')['å—ç†è¨˜å·']
                .first()
                .to_dict()
            )
        else:
            filing_name_to_symbol = {}
        
        # Get all filing types (æ–½è¨­åŸºæº–) from target and top 20 institutions
        all_filing_types = set()
        
        # Get target institution's filing types
        target_institution_number = institution_data.iloc[0]['åŒ»ç™‚æ©Ÿé–¢ç•ªå·']
        target_filing_types = institution_filings_by_number.get(target_institution_number, set())
        all_filing_types.update(target_filing_types)
        
        # Get top 20 institutions' filing types
        for institution_name in top_20_institutions:
            institution_number = institution_number_mapping.get(institution_name)
            if institution_number:
                filing_types = institution_filings_by_number.get(institution_number, set())
                all_filing_types.update(filing_types)
        
        all_filing_types = sorted(list(all_filing_types))
        
        if all_filing_types and top_20_institutions:
            # Build data for cross-tabulation
            rows_data = []
            
            for filing_type in all_filing_types:
                row_data = {
                    'å—ç†å±Šå‡ºåç§°': filing_type,
                    'å—ç†è¨˜å·': filing_name_to_symbol.get(filing_type, '')
                }
                
                # First, add target institution's filing status
                target_filing_types_set = institution_filings_by_number.get(target_institution_number, set())
                row_data[selected_institution] = filing_type in target_filing_types_set
                
                # Then, add top 20 institutions' filing status
                for institution_name in top_20_institutions:
                    institution_number = institution_number_mapping.get(institution_name)
                    if institution_number:
                        filing_types_set = institution_filings_by_number.get(institution_number, set())
                        row_data[institution_name] = filing_type in filing_types_set
                    else:
                        row_data[institution_name] = False
                
                rows_data.append(row_data)
            
            # Create DataFrame with å—ç†å±Šå‡ºåç§° and å—ç†è¨˜å· as columns
            cross_tab_df = pd.DataFrame(rows_data)
            # Set å—ç†å±Šå‡ºåç§° as index for filtering, but we'll display it as a column
            cross_tab_df = cross_tab_df.set_index('å—ç†å±Šå‡ºåç§°')
            
            # Filter: Show only filing types that target institution has NOT filed
            show_only_unfiled = st.checkbox(
                "å¯¾è±¡åŒ»ç™‚æ©Ÿé–¢ãŒæœªå±Šã®æ–½è¨­åŸºæº–ã®ã¿è¡¨ç¤º",
                value=False,
                key='show_only_unfiled_filter'
            )
            
            if show_only_unfiled:
                # Filter rows where target institution column is False
                filtered_cross_tab_df = cross_tab_df[cross_tab_df[selected_institution] == False].copy()
            else:
                filtered_cross_tab_df = cross_tab_df.copy()
            
            # Reset index to display å—ç†å±Šå‡ºåç§° as a regular column
            display_df = filtered_cross_tab_df.reset_index()
            
            # Reorder columns: å—ç†å±Šå‡ºåç§°, å—ç†è¨˜å·, then institution columns
            institution_columns = [selected_institution] + top_20_institutions
            display_columns = ['å—ç†å±Šå‡ºåç§°', 'å—ç†è¨˜å·'] + institution_columns
            display_df = display_df[display_columns]
            
            # Display the table
            st.dataframe(
                display_df,
                width='stretch',
                hide_index=True
            )
        
        # Add explanation about Jaccard similarity at the end
        st.divider()
        st.write("### ğŸ“– é¡ä¼¼åº¦ã®è¨ˆç®—æ–¹æ³•ã«ã¤ã„ã¦")
        st.markdown("""
        **Jaccardä¿‚æ•°ï¼ˆJaccard similarity coefficientï¼‰**ã‚’ä½¿ç”¨ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™ã€‚
        
        Jaccardä¿‚æ•°ã¯ã€2ã¤ã®é›†åˆãŒã©ã‚Œã ã‘ä¼¼ã¦ã„ã‚‹ã‹ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã€ä»¥ä¸‹ã®å¼ã§è¨ˆç®—ã•ã‚Œã¾ã™ï¼š
        
        $$
        J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|} = \\frac{\\text{å…±é€šè¦ç´ æ•°}}{\\text{å…¨è¦ç´ æ•°}}
        $$
        
        **å…·ä½“ä¾‹ï¼š**
        
        åŒ»ç™‚æ©Ÿé–¢Aã®å±Šå‡ºæ–½è¨­åŸºæº–ï¼š`{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™1, ç‰¹æ²è¨ºç™‚æ–™2}`
        
        åŒ»ç™‚æ©Ÿé–¢Bã®å±Šå‡ºæ–½è¨­åŸºæº–ï¼š`{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™2, ç‰¹æ²è¨ºç™‚æ–™3}`
        
        - **å…±é€šã™ã‚‹å±Šå‡ºï¼ˆç©é›†åˆï¼‰**: `{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™2}` â†’ 2å€‹
        - **ã™ã¹ã¦ã®å±Šå‡ºï¼ˆå’Œé›†åˆï¼‰**: `{åŸºæœ¬è¨ºç™‚æ–™, ç‰¹æ²è¨ºç™‚æ–™1, ç‰¹æ²è¨ºç™‚æ–™2, ç‰¹æ²è¨ºç™‚æ–™3}` â†’ 4å€‹
        - **Jaccardä¿‚æ•°**: 2 Ã· 4 = 0.5 (50%)
        
        Jaccardä¿‚æ•°ã¯0ã‹ã‚‰1ã®å€¤ã‚’å–ã‚Šã€1ã«è¿‘ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ãã€0ã«è¿‘ã„ã»ã©é¡ä¼¼åº¦ãŒä½ã„ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
        """)
else:
    st.info("åŒ»ç™‚æ©Ÿé–¢æ¤œç´¢ãƒšãƒ¼ã‚¸ã‹ã‚‰åŒ»ç™‚æ©Ÿé–¢ã‚’æ¤œç´¢ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚")
